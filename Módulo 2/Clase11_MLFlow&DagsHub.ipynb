{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones comunes para un ambiente de `MLflow Tracking`.\n",
    "![](https://mlflow.org/docs/latest/_images/tracking-setup-overview.png)\n",
    "\n",
    "### Escenario 2\n",
    "```python\n",
    "# set mlflow tracking uri\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "```\n",
    "\n",
    "### Escenario 3\n",
    "MLFlow remoto\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('url/remote/server')\n",
    "```\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## `MLflow`: Beneficios\n",
    "* El `Tracking server` puede ser fácilmente desplegado en la nube\n",
    "* Compartir experimentos con otros Data Scientists\n",
    "* Colaborar con otros para construir y desplegar modelos\n",
    "* Dar más visibilidad de los esfuerzos del equipo de Data Science.\n",
    "\n",
    "## `MLflow`: Problemas cuando se ejecutan servidores remotos compartidos\n",
    "* Seguridad:\n",
    "    * Restringir el acceso al server (por ejemplo a través de una VPN)\n",
    "* Isolation:\n",
    "    * Definir un estándar para nombrar experimentos, modelos y un conjunto de tags predeterminados.\n",
    "    * Restringir el acceso a los artefactos  \n",
    "\n",
    "## `MLflow`: Limitaciones\n",
    "* **Autenticación y Usuarios:** La versión open source de `MLflow` no provee ningún tipo de autenticación\n",
    "* **Versionamiento de datos** \n",
    "    * Para asegurar total reproducibilidad, necesitamos versionar los datos que se usan para entrenar el modelo.\n",
    "    * `MLflow` no provee una solución para eso, pero hay maneras de mitigarlo\n",
    "* **Monitoreo del modelo y datos:** Veremos la herramienta adecuada para este fin "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DagsHub\n",
    " <div style=\"text-align:center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/611655/181510038-e38f4001-c304-411e-8f45-f71554eb9763.png\" alt=\"DagsHub Logo\">\n",
    "</div>\n",
    "\n",
    "## Introducción:\n",
    "DagsHub es una plataforma revolucionaria que se describe como el \"GitHub para el aprendizaje automático\". Permite a los científicos de datos y desarrolladores de aprendizaje automático gestionar y colaborar en sus proyectos de manera eficiente, asegurando la reproducibilidad y el control de versiones.\n",
    "\n",
    "## Características Clave:\n",
    "1. **Control de Versiones**: Realiza un seguimiento de los cambios en los datos, el código y los modelos, garantizando un historial completo de tu proyecto de aprendizaje automático.\n",
    "2. **Colaboración**: Facilita la colaboración dentro de los equipos al permitir que varios usuarios trabajen en el mismo proyecto manteniendo el historial de versiones.\n",
    "3. **Versionado de Datos**: Realiza un seguimiento de las versiones de los datos, lo que facilita la reproducción de experimentos y el intercambio de conjuntos de datos.\n",
    "4. **Reproducibilidad**: Asegura que los experimentos se puedan replicar con el mismo código, datos y entorno.\n",
    "5. **Interfaz Web**: Ofrece una interfaz web intuitiva para organizar y gestionar proyectos de aprendizaje automático.\n",
    "6. **Repositorios Públicos y Privados**: Ofrece tanto repositorios públicos como privados para compartir proyectos de manera abierta o segura.\n",
    "7. **Seguimiento de Experimentos**: Registra todos los detalles de los experimentos de aprendizaje automático, lo que facilita el análisis y la comparación de resultados.\n",
    "8. **Integración**: Se integra fácilmente con herramientas y formatos de código abierto populares, como Jupyter notebooks y Git.\n",
    "9. **Organización de Proyectos**: Proporciona herramientas para mantener estructurado y bien documentado tu proyecto de aprendizaje automático.\n",
    "\n",
    "\n",
    "## Dagshub\n",
    "\n",
    "1. Creamos una cuenta [aquí](https://dagshub.com/user/sign_up). Se puede asociar con la cuenta de GitHub.\n",
    "2. Cambiar contraseña.\n",
    "3. Crear un primer repositorio."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Actividad\n",
    "Vamos a prepara el ambiente de trabajo para la siguiente clase:\n",
    "\n",
    "1. Creamos un repositorio en `Github` llamado `nyc-taxi-time-prediction`\n",
    "2. Vinculamos el repositorio a nuestra cuenta de `Dagshub`\n",
    "3. Clonamos el repositorio de `Github` en nuestro local\n",
    "4. Creamos un ambiente virtual\n",
    "5. Crear una branch `experiments`\n",
    "6. Crear un directorio `experiments` en la carpeta raíz del proyecto\n",
    "7. Crer un `jupyter-notebook` dentro de dicho directorio con el nombre `model_experiments.ipynb`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![ml flow cheatsheet](images/mlflow-cheatsheet.png)\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vamos a reutilizar el código que ya hemos usado\n",
    "\n",
    "```bash\n",
    "pip install mlflow==2.16.1 dagshub==0.3.35 jupyter==1.1.1 xgboost==2.1.1 hyperopt==0.2.7\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Copiar dataset en una carpeta `data`"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the directory if it doesn't exist\n",
    "!mkdir -p ../data\n",
    "\n",
    "# Download files using curl\n",
    "!curl -o ../data/green_tripdata_2024-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-01.parquet\n",
    "!curl -o ../data/green_tripdata_2024-02.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-02.parquet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importar las librerías necesarias y definir función para importar los datos"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train = read_dataframe('../data/green_tripdata_2024-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2024-02.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature Engineering"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One Hot Encoding"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical = ['PU_DO']  #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir el `tracking URI` y el nombre del experimento"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "\n",
    "dagshub.init(url=\"<url/del/repo>\", mlflow=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir los `dataset` como objetos de `mlflow` para poderlos trackear"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2024-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2024-02\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Subir los dataset al storage que nos brinda `dagshub`"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora vamos a entrenar un modelo `xgboost`\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import pathlib"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir los `dataset` a trabajar."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir la función objetivo"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "         \n",
    "        # Tag model\n",
    "        mlflow.set_tag(\"model_family\", \"xgboost\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=10\n",
    "        )\n",
    "        \n",
    "        # Log xgboost model with artifact_path\n",
    "        mlflow.xgboost.log_model(booster, artifact_path=\"model\")\n",
    "         \n",
    "        # Predict in the val dataset\n",
    "        y_pred = booster.predict(valid)\n",
    "        \n",
    "        # Calculate metric\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        # Log performance metric\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir el espacio de búsqueda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.xgboost.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Xgboost Hyper-parameter Optimization\", nested=True):\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=Trials()\n",
    "    )\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "    \n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Log tags\n",
    "    mlflow.set_tags(\n",
    "        tags={\n",
    "            \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "            \"optimizer_engine\": \"hyper-opt\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "            \"feature_set_version\": 1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Log a fit model instance\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "        \n",
    "    y_pred = booster.predict(valid)\n",
    "    \n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "        \n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_params",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora vamos a registrar el mejor modelo en el `model registry` y usarlo para hacer predicciones"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_id = input(\"Ingrese el run_id\")\n",
    "run_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=run_uri,\n",
    "    name=\"nyc-taxi-model\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "client.update_registered_model(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    description=\"Model registry for the NYC Taxi Time Prediction Project\",\n",
    ")\n",
    "\n",
    "new_alias = \"champion\"\n",
    "date = datetime.today()\n",
    "model_version = \"1\"\n",
    "\n",
    "# create \"champion\" alias for version 1 of model \"nyc-taxi-model\"\n",
    "client.set_registered_model_alias(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    alias=new_alias,\n",
    "    version=model_version\n",
    ")\n",
    "\n",
    "client.update_model_version(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_alias} on {date}\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"nyc-taxi-model\"\n",
    "alias = \"champion\"\n",
    "\n",
    "model_uri = f\"models:/{model_name}@{alias}\"\n",
    "\n",
    "champion_version = mlflow.pyfunc.load_model(\n",
    "    model_uri=model_uri\n",
    ")\n",
    "\n",
    "champion_version.predict(X_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tarea y actividad en clase.\n",
    "\n",
    "1. Hacer merge de la rama que trabajamos a main.\n",
    "2. Crear una nueva rama que se llame `feat: tarea 5`.\n",
    "3. Crear un nuevo `jupyter-notebook` llamado `challenger-experiments.ipynb` en la rama creada anteriormente\n",
    "4. Hacer dos `parent experiments` con `Gradient Boost` y `Random Forest` regressors en donde cada uno tenga `child experiments` con búsqueda de hyper-parámetros. Puede usar cualquier libreraría con la que se sienta cómodo: `hyperopt`, `optuna`, `scikit-learn` (Grid Search, Random Search, Halving Search etc)\n",
    "5. Registrar el modelo con la mejor métrica de los obtenidos en dichos experimentos en el `model registry` en el mismo modelo ya previamente creado `nyc-taxi-model`.\n",
    "6. Asígnele el alias `challenger`\n",
    "7. Descargue en la carpeta `data` el conjunto de datos correspondiente a marzo del 2024\n",
    "8. Guardela en el `storage` disponible de `mlflow`\n",
    "9. Use ese conjunto de datos para probarlo sobre los modelos con el alias `champion` y `challenger`\n",
    "10. Obtenga la métrica de cada modelo\n",
    "11. Decida si el nuevo modelo `challenger` debe ser promovido a `champion` o no. Use los criterios que usted como Data Scientis considere relevantes y justifique la respuesta.\n",
    "12. Abrir un `PR` con los cambios hechos en la rama `feat: tarea 5` hacia la rama `main`.\n",
    "\n",
    "\n",
    "Habrá dos entregas divididas de la siguiente manera:\n",
    "\n",
    "1. **Trabajo en clase hoy Martes 17 de Septiembre de 2024.** Para esta entrega, hacer un commit con el siguiente mensaje `feat: entrega trabajo en clase` con los avances realizados en clase.\n",
    "\n",
    "2. **Tarea: Viernes 20 de Septiembre de 2024 a las 19:55.** Esta entrega debe contener todo lo descrito anteriormente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
