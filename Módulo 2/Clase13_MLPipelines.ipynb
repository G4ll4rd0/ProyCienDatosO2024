{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1792ca886606664",
   "metadata": {},
   "source": [
    "# 0. Introducción a Cron y Logger en Python\n",
    "\n",
    "## 0.1. ¿Qué es **Cron**?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cron\n",
    "\n",
    "La utilidad de línea de comandos **cron** es un **programador de tareas** (job scheduler) en sistemas operativos basados en `Unix`. Su función es permitir a los usuarios, quienes mantienen y configuran entornos de software, programar trabajos (jobs), como comandos o scripts de shell, conocidos también como **cron jobs**, para ejecutarse periódicamente en tiempos, fechas o intervalos fijos.\n",
    "\n",
    "Cron se utiliza típicamente para automatizar tareas de mantenimiento o administración del sistema. Sin embargo, su naturaleza general lo hace útil para otras actividades, como descargar archivos desde Internet o revisar correos electrónicos a intervalos regulares. \n",
    "\n",
    "**Cron** es más adecuado para tareas repetitivas.\n",
    "\n",
    "El nombre de **cron** proviene de \"Chronos\", la palabra griega para tiempo.\n",
    "\n",
    "```bash\n",
    "# * * * * * <command to execute>\n",
    "# | | | | |\n",
    "# | | | | day of the week (0–6) (Sunday to Saturday; 7 is also Sunday on some systems)\n",
    "# | | | month (1–12)             \n",
    "# | | day of the month (1–31)\n",
    "# | hour (0–23)\n",
    "# minute (0–59)\n",
    "```\n",
    "\n",
    "### Vamos a jugar\n",
    "https://crontab.guru/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dcd94c5871c6f",
   "metadata": {},
   "source": [
    "## 0.2. ¿Qué es **Logger** en Python?\n",
    "\n",
    "A medida que nuestros scripts se vuelven más complejos, necesitamos una forma de **monitorear** lo que está sucediendo en ellos, especialmente cuando algo sale mal. Aquí es donde entra **logging**. \n",
    "\n",
    "`Python` tiene un módulo integrado llamado `logging` que permite registrar eventos o mensajes en diferentes niveles: \n",
    "\n",
    "- **DEBUG**: Información detallada, usualmente para desarrolladores.\n",
    "- **INFO**: Confirmación de que las cosas están funcionando como se esperaba.\n",
    "- **WARNING**: Algo inesperado, pero no crítico.\n",
    "- **ERROR**: Fallos debido a un problema en el programa.\n",
    "- **CRITICAL**: Error grave, usualmente detiene el programa.\n",
    "\n",
    "Para usar **logger** en un script de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf3da74964194d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 20:27:25,689 - DEBUG - Este es un mensaje de depuración\n",
      "2024-09-24 20:27:25,691 - INFO - Este es un mensaje informativo\n",
      "2024-09-24 20:27:25,692 - WARNING - Este es una advertencia\n",
      "2024-09-24 20:27:25,692 - ERROR - Este es un mensaje de error\n",
      "2024-09-24 20:27:25,693 - CRITICAL - Este es un error crítico\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configuración básica de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "\n",
    "# Ejemplo de cómo registrar eventos\n",
    "logging.debug(\"Este es un mensaje de depuración\")\n",
    "logging.info(\"Este es un mensaje informativo\")\n",
    "logging.warning(\"Este es una advertencia\")\n",
    "logging.error(\"Este es un mensaje de error\")\n",
    "logging.critical(\"Este es un error crítico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee57a2a84eb1a8",
   "metadata": {},
   "source": [
    "### Configuración de **Logger** en Python\n",
    "\n",
    "El módulo `logging` de Python permite una gran flexibilidad para definir cómo y dónde se registran los mensajes. Algunas de las configuraciones más comunes son:\n",
    "\n",
    "#### 1. **Nivel de Log** (`level`)\n",
    "El nivel del log define la gravedad de los mensajes que se quieren capturar. Algunos niveles de log comunes incluyen:\n",
    "- `DEBUG`: Información detallada, útil para depuración.\n",
    "- `INFO`: Confirmaciones de que el programa está funcionando como se espera.\n",
    "- `WARNING`: Indica que algo inesperado sucedió, pero el programa sigue funcionando.\n",
    "- `ERROR`: Señala errores más graves, pero que no detienen la ejecución.\n",
    "- `CRITICAL`: Errores graves que probablemente detendrán el programa.\n",
    "\n",
    "Cuando configuramos un **nivel de log**, sólo se capturan los mensajes de ese nivel o superiores. Por ejemplo, si establecemos el nivel en `WARNING`, se registrarán los mensajes `WARNING`, `ERROR` y `CRITICAL`, pero no los `DEBUG` o `INFO`.\n",
    "\n",
    "#### 2. **Formato del mensaje** (`format`)\n",
    "El formato del mensaje permite personalizar cómo se muestran los logs. Algunos componentes útiles en el formato son:\n",
    "- `%(asctime)s`: La fecha y hora en que se registró el mensaje.\n",
    "- `%(levelname)s`: El nivel del log (DEBUG, INFO, WARNING, etc.).\n",
    "- `%(message)s`: El mensaje que se ha registrado.\n",
    "- `%(name)s`: El nombre del logger.\n",
    "- `%(threadName)s`: El nombre del hilo desde donde se emitió el log.\n",
    "- `%(processName)s`: El nombre del proceso que emitió el log.\n",
    "\n",
    "#### 3. **Formato de fecha y hora** (`datefmt`)\n",
    "El parámetro `datefmt` permite personalizar el formato de la fecha y hora que se incluye en los mensajes de log. Puedes usar cualquier formato de fecha y hora compatible con Python, como el que se usa en `strftime`. Esto es útil para ajustar el formato a las necesidades específicas de tu aplicación.\n",
    "\n",
    "##### Códigos de Formato Comunes\n",
    "\n",
    "Aquí tienes algunos códigos de formato comúnmente utilizados que puedes usar con `strftime`:\n",
    "\n",
    "| Código | Significado                           | Ejemplo de Salida       |\n",
    "|--------|---------------------------------------|--------------------------|\n",
    "| `%Y`   | Año con siglo                         | `2024`                   |\n",
    "| `%y`   | Año sin siglo (00-99)                | `24`                     |\n",
    "| `%m`   | Mes como un decimal con ceros (01-12)| `09`                     |\n",
    "| `%B`   | Nombre completo del mes               | `Septiembre`             |\n",
    "| `%b`   | Nombre abreviado del mes              | `Sep`                    |\n",
    "| `%d`   | Día del mes (01-31)                  | `24`                     |\n",
    "| `%H`   | Hora (00-23)                         | `14`                     |\n",
    "| `%I`   | Hora (01-12)                         | `02`                     |\n",
    "| `%M`   | Minuto (00-59)                       | `05`                     |\n",
    "| `%S`   | Segundo (00-59)                      | `30`                     |\n",
    "| `%p`   | AM o PM                              | `PM`                     |\n",
    "| `%A`   | Nombre completo del día de la semana | `Martes`                 |\n",
    "| `%a`   | Nombre abreviado del día de la semana | `Mar`                    |\n",
    "| `%j`   | Día del año (001-366)                | `267`                    |\n",
    "| `%U`   | Número de semana del año (00-53)     | `39`                     |\n",
    "| `%W`   | Número de semana del año (00-53), basado en lunes | `39`          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb84a8ef7326c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 20:30:56,458 - INFO - Respaldo iniciado\n",
      "2024-09-24 20:30:56,460 - ERROR - Error: La base de datos no existe\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "                           \n",
    "logging.basicConfig(\n",
    "    # filename='backup.log', \n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "     datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")\n",
    "\n",
    "def hacer_respaldo():\n",
    "    try:\n",
    "        # Supongamos que aquí ocurre el proceso de respaldo\n",
    "        logger.info(\"Respaldo iniciado\")\n",
    "        # Simulación de respaldo\n",
    "        if os.path.exists('base_de_datos.db'):\n",
    "            logger.info(\"Respaldo exitoso\")\n",
    "        else:\n",
    "            logger.error(\"Error: La base de datos no existe\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Error crítico durante el respaldo: {e}\")\n",
    "\n",
    "# Ejecutamos la función\n",
    "hacer_respaldo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614b0b6d3b18ce7",
   "metadata": {},
   "source": [
    "Ahora sí, empecemos la clase de hoy\n",
    "\n",
    "# 1. Machine Learning Pipeline a.k.a Workflow Orchestration\n",
    "\n",
    "> Un pipeline de machine learning es una serie de pasos secuenciales y automatizados que se siguen para entrenar, evaluar y desplegar un modelo de machine learning. \n",
    "> El objetivo principal de un pipeline es automatizar el proceso repetitivo de transformar datos crudos en un modelo que pueda usarse en producción.\n",
    "\n",
    "    \n",
    "### Yo tratando de explicar el orden de ejecución de las celdas de mi `jupyter-notebook`:\n",
    "\n",
    " <img style=\"display: block; margin: auto;\" src=\"./images/orchestration-meme.png\" width=\"580\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e8ef3c5d729af1",
   "metadata": {},
   "source": [
    "Revisemos lo que hemos hecho hasta ahora con nuestro código...\n",
    "1. Downloading data ----> Ingestion\n",
    "2. Transforming the data ----> Filtering, removing outliers\n",
    "3. Preparing data for ML ----> Feature Engineering\n",
    "4. Hyper-parameter tunning ----> Best params\n",
    "5. Train the final model ----> Best params\n",
    "6. Registry the final model\n",
    "\n",
    "**Problemas:**\n",
    "- Un cuaderno gigante\n",
    "- Sin muchas instrucciones\n",
    "- Poco legible para cualquier persona\n",
    "- No escalable ni mantenible\n",
    "- Podríamos decir que es un `workflow`, ya que se debe ejecutar en un orden específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_data(year, month):\n",
    "    ...\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    ...\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    ...\n",
    "    return X, y\n",
    "\n",
    "def find_best_model(X, y):\n",
    "    ...\n",
    "    return params\n",
    "\n",
    "def train_model(X, y, params):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    df = download_data(2024,1)\n",
    "    df = prepare_data(df)\n",
    "    X, y = feature_engineering(df)\n",
    "    model_params = find_best_model(X, y)\n",
    "    model = train_model(X, y, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b404890b7646d",
   "metadata": {},
   "source": [
    "Mucho mejor, no?\n",
    "\n",
    "Pero sigue teniendo problemas:\n",
    "- Lo podemos agendar?\n",
    "- Qué pasa si tengo múltiples archivos?\n",
    "- O si no lo quiero ejecutar en mi máquina local?\n",
    "- Qué pasa si una de las funciones falla? Si es solamente temporal el fallo?\n",
    "- Y si queremos notificar que ese error ocurrió a algún administrador?\n",
    "\n",
    "Hay múltiples herramientas que vienen a solventar esos problemas:\n",
    "\n",
    "- [Apache Airflow](https://airflow.apache.org/)\n",
    "- [Prefect](https://www.prefect.io/)\n",
    "- [Mage](https://www.mage.ai/)\n",
    "- [Dagster](https://dagster.io/)\n",
    "- [Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/)\n",
    "- [Scikitlearn Pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eaecb1d50d0eb2",
   "metadata": {},
   "source": [
    "# 2. Prefect\n",
    "\n",
    "## 2.1. Definiciones en **Prefect**\n",
    "\n",
    "### 2.1.1. **Task (Tarea)**\n",
    "https://docs.prefect.io/3.0/develop/write-tasks\n",
    "\n",
    "En **Prefect**, una `task` es la unidad más básica de trabajo en un flujo de Prefect. Una `task` representa una operación individual que se ejecuta dentro de un flujo de trabajo (`flow`). Puedes convertir cualquier función de Python en una `task` agregando el decorador `@task`. \n",
    "\n",
    "Las tasks pueden:\n",
    "- **Tomar entradas, realizar un trabajo y devolver salidas**: Realizan operaciones con los datos que reciben y devuelven resultados.\n",
    "- **Cachear su ejecución a través de múltiples invocaciones**: Evitar repetir cálculos si una task ya se ejecutó anteriormente con los mismos inputs.\n",
    "- **Encapsular la lógica del flujo en unidades reutilizables**: Pueden ser utilizadas en diferentes flows.\n",
    "- **Usar logging automático** para capturar detalles de ejecución, etiquetas (tags) y estado final.\n",
    "- **Ejecutarse de forma concurrente**: Permiten paralelismo en la ejecución de tareas.\n",
    "- **Definirse en el mismo archivo que el `flow` o importarse de módulos**.\n",
    "- **Llamarse desde `flows` u otras `tasks`**.\n",
    "\n",
    "**Ejemplo de una tarea:**\n",
    "\n",
    "```python\n",
    "from prefect import task\n",
    "\n",
    "@task\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d69588b800985b",
   "metadata": {},
   "source": [
    "### 2.1.2. **Flow (Flujo)**\n",
    "https://docs.prefect.io/3.0/develop/write-flows\n",
    "\n",
    "Un `flow` en **Prefect** es una colección de `tasks` que se ejecutan de manera organizada y coordinada. \n",
    "\n",
    "Un `flow` define cómo las `tasks` interactúan entre sí y permite orquestar la ejecución de múltiples `tasks` con reglas específicas, como dependencias, condicionales y paralelismo. \n",
    "\n",
    "Además, un `flow` puede manejar `tasks` de manera secuencial o en paralelo, así como gestionarlas en función de eventos externos.\n",
    "\n",
    "Los flows se definen como funciones en Python, y pueden tomar entradas, realizar tareas y devolver resultados. Cualquier función Python puede convertirse en un flow de Prefect añadiendo el decorador `@flow`:\n",
    "```python\n",
    "from prefect import flow\n",
    "\n",
    "@flow\n",
    "def mi_flujo_principal():\n",
    "    resultado = sumar(3, 4)\n",
    "    print(f\"El resultado es {resultado}\")\n",
    "```\n",
    "#### Capacidades de los Flows en Prefect:\n",
    "\n",
    "Cuando una función se convierte en un `flow`, adquiere las siguientes capacidades:\n",
    "\n",
    "- **Seguimiento automático de metadatos** sobre las ejecuciones del flujo, como el tiempo de ejecución y el estado final.\n",
    "- **Registro de cada estado** que el flujo alcanza, lo que permite observar y actuar sobre cada transición en la ejecución del flow.\n",
    "- **Validación de tipos de los argumentos** de entrada como parámetros del flujo de trabajo.\n",
    "- **Reintentos automáticos** en caso de fallo, con límites y retrasos configurables.\n",
    "- **Timeouts** para evitar que los flujos de trabajo se ejecuten durante demasiado tiempo sin control.\n",
    "- **Capacidad de despliegue**, lo que expone una API para interactuar con el flow de manera remota.\n",
    "\n",
    "Los `flows` se identifican de forma única por su nombre. Puedes especificar un nombre para el `flow` utilizando el parámetro `name`:\n",
    "\n",
    "```python\n",
    "@flow(name=\"Mi Flujo\")\n",
    "def mi_flujo() -> str:\n",
    "    return \"¡Hola, mundo!\"\n",
    "```\n",
    "\n",
    "Si no proporcionas un nombre, Prefect usará el nombre de la función del flow.\n",
    "\n",
    "#### Ejecución de `Flows`:\n",
    "\n",
    "Una ejecución de flow (**flow run**) es una ejecución individual de un `flow`.\n",
    "\n",
    "Puedes ejecutar un `flow` llamándolo por su nombre de función, de la misma manera que lo harías con una función normal de `Python`. También puedes ejecutar un `flow` mediante:\n",
    "\n",
    "- **Programadores externos**, como `cron`, para invocar la función del `flow`.\n",
    "- **Desplegar el flow en Prefect Cloud** o en un servidor auto-hospedado de Prefect.\n",
    "- **Iniciar una ejecución de flow a través de un cronograma**, la interfaz de usuario de Prefect, o la API de Prefect.\n",
    "\n",
    "Sin importar cómo ejecutes el `flow`, `Prefect` monitorea su ejecución, capturando el estado para observabilidad. Además, puedes registrar una variedad de metadatos sobre las ejecuciones del flow para monitoreo, resolución de problemas y auditoría."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edee0e98d84bbc0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.1.3. Diferencias entre `Task` y `Flow`:\n",
    "\n",
    "- **Task**: Una tarea individual, pequeña y específica que ejecuta una operación.\n",
    "- **Flow**: Un contenedor que organiza y coordina la ejecución de varias tasks, permitiendo su orquestación.\n",
    "\n",
    "### 2.1.4. Ejemplo Completo de Task y Flow en Prefect:\n",
    "\n",
    "```python\n",
    "from prefect import task, flow\n",
    "\n",
    "@task\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "\n",
    "@flow\n",
    "def mi_flujo_principal():\n",
    "    resultado = sumar(3, 4)\n",
    "    print(f\"El resultado es {resultado}\")\n",
    "\n",
    "# Ejecutar el flow\n",
    "mi_flujo_principal()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d1c873fd6836e",
   "metadata": {},
   "source": [
    "## 2.2 Uso de `Prefect`\n",
    "\n",
    "```bash\n",
    "pip install prefect\n",
    "prefect version\n",
    "```\n",
    "\n",
    "Ahora vamos a inicializar un servidor de `prefect`\n",
    "\n",
    "```bash\n",
    "prefect server start\n",
    "```\n",
    "\n",
    "Vamos a ver un `flow` sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e81b69181ae7d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T07:48:48.690700Z",
     "start_time": "2024-09-24T07:48:46.007790Z"
    }
   },
   "outputs": [],
   "source": [
    "import httpx\n",
    "from prefect import flow, task\n",
    "\n",
    "\n",
    "@task(retries=4, retry_delay_seconds=1, log_prints=True)\n",
    "def fetch_cat_fact():\n",
    "    cat_fact = httpx.get(\"https://f3-vyx5c2hfpq-ue.a.run.app/\")\n",
    "    #An endpoint that is designed to fail sporadically\n",
    "    if cat_fact.status_code >= 400:\n",
    "        raise Exception()\n",
    "    print(cat_fact.text)\n",
    "\n",
    "\n",
    "@flow\n",
    "def fetch():\n",
    "    fetch_cat_fact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e522a6a8473229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T07:49:36.657027Z",
     "start_time": "2024-09-24T07:49:31.673396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:25.874 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'free-boobook'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:25.874 | \u001B[36mINFO\u001B[0m    | prefect.engine - Created flow run\u001B[35m 'free-boobook'\u001B[0m for flow\u001B[1;35m 'fetch'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:25.876 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/12ee3460-35e5-4aec-b0b5-ca16275bf6a8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:25.876 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/12ee3460-35e5-4aec-b0b5-ca16275bf6a8\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:25.942 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-ba8' - Created task run 'fetch_cat_fact-ba8' for task 'fetch_cat_fact'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:25.942 | \u001B[36mINFO\u001B[0m    | Task run 'fetch_cat_fact-ba8' - Created task run 'fetch_cat_fact-ba8' for task 'fetch_cat_fact'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:28.109 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-ba8' - A healthy cat has a temperature between 38 and 39 degrees Celcius.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:28.109 | \u001B[36mINFO\u001B[0m    | Task run 'fetch_cat_fact-ba8' - A healthy cat has a temperature between 38 and 39 degrees Celcius.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:28.114 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-ba8' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:28.114 | \u001B[36mINFO\u001B[0m    | Task run 'fetch_cat_fact-ba8' - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:28.158 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'free-boobook'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:28.158 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'free-boobook'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2a5180d8f6bc9",
   "metadata": {},
   "source": [
    "Ahora veamos el concepto de `subflows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82f34f9a0f83186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow\n",
    "\n",
    "\n",
    "@flow(name=\"Cat fact\")\n",
    "def fetch_cat_fact():\n",
    "    \"\"\"A flow that gets a cat fact\"\"\"\n",
    "    return httpx.get(\"https://catfact.ninja/fact?max_length=140\").json()[\"fact\"]\n",
    "\n",
    "\n",
    "@flow(name=\"Dog fact\")\n",
    "def fetch_dog_fact():\n",
    "    \"\"\"A flow that gets a dog fact\"\"\"\n",
    "    return httpx.get(\n",
    "        \"https://dogapi.dog/api/v2/facts\",\n",
    "        headers={\"accept\": \"application/json\"},\n",
    "    ).json()[\"data\"][0][\"attributes\"][\"body\"]\n",
    "\n",
    "\n",
    "@flow(name=\"Animals fact\", log_prints=True)\n",
    "def animal_facts():\n",
    "    cat_fact = fetch_cat_fact()\n",
    "    dog_fact = fetch_dog_fact()\n",
    "    print(f\"🐱: {cat_fact} \\n🐶: {dog_fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa2d43e134d6635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.758 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Animals fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.758 | \u001B[36mINFO\u001B[0m    | prefect.engine - Created flow run\u001B[35m 'towering-antelope'\u001B[0m for flow\u001B[1;35m 'Animals fact'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.759 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/a79ab48a-ba66-4728-9b64-2ae2b3ab593b</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.759 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/a79ab48a-ba66-4728-9b64-2ae2b3ab593b\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.913 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'delicate-rattlesnake'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Cat fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.913 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - Created subflow run\u001B[35m 'delicate-rattlesnake'\u001B[0m for flow\u001B[1;35m 'Cat fact'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.915 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/4c8c1db1-73e3-4626-bb9e-d44d2f79762f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.915 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/4c8c1db1-73e3-4626-bb9e-d44d2f79762f\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:28.261 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'delicate-rattlesnake'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:28.261 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'delicate-rattlesnake'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:28.362 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lilac-chimpanzee'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Dog fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:28.362 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - Created subflow run\u001B[35m 'lilac-chimpanzee'\u001B[0m for flow\u001B[1;35m 'Dog fact'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:28.364 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/d8e0e718-6ef0-4377-a618-21c18fbc62f8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:28.364 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/d8e0e718-6ef0-4377-a618-21c18fbc62f8\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:29.106 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lilac-chimpanzee'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:29.106 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'lilac-chimpanzee'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:29.108 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - 🐱: Grown cats have 30 teeth. Kittens have about 26 temporary teeth, which they lose when they are about 6 months old.\n",
       "🐶: Hyenas aren't actually dogs. They are more closely related to cats.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:29.108 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - 🐱: Grown cats have 30 teeth. Kittens have about 26 temporary teeth, which they lose when they are about 6 months old.\n",
       "🐶: Hyenas aren't actually dogs. They are more closely related to cats.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:29.139 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:29.139 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animal_facts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982db0e9319221ee",
   "metadata": {},
   "source": [
    "Ahora vamos a hacerlo para nuestro pipeline de entrenamiento en nuestro proyecto `nyc-taxi-time-prediction`\n",
    "\n",
    "- Vamos a crear una nueva rama `feat/training_orchestration`. \n",
    "- Vamos a crear un nuevo directorio `training pipeline`\n",
    "- crear un archivo llamado `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b026cb8548f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mlflow\n",
    "import pathlib\n",
    "import dagshub\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "def read_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data into DataFrame\"\"\"\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df[\"duration\"] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_features(df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "    \"\"\"Add features to the model\"\"\"\n",
    "    df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + \"_\" + df_train[\"DOLocationID\"]\n",
    "    df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + \"_\" + df_val[\"DOLocationID\"]\n",
    "\n",
    "    categorical = [\"PU_DO\"]  #'PULocationID', 'DOLocationID']\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    train_dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "    val_dicts = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    y_train = df_train[\"duration\"].values\n",
    "    y_val = df_val[\"duration\"].values\n",
    "    return X_train, X_val, y_train, y_val, dv\n",
    "\n",
    "def hyper_parameter_tunning(X_train, X_val, y_train, y_val, dv):\n",
    "    \n",
    "    mlflow.xgboost.autolog()\n",
    "    \n",
    "    training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2024-01\")\n",
    "    \n",
    "    validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2024-02\")\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    def objective(params):\n",
    "        with mlflow.start_run(nested=True):\n",
    "             \n",
    "            # Tag model\n",
    "            mlflow.set_tag(\"model_family\", \"xgboost\")\n",
    "            \n",
    "            # Train model\n",
    "            booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=train,\n",
    "                num_boost_round=100,\n",
    "                evals=[(valid, 'validation')],\n",
    "                early_stopping_rounds=10\n",
    "            )\n",
    "            \n",
    "            # Predict in the val dataset\n",
    "            y_pred = booster.predict(valid)\n",
    "            \n",
    "            # Calculate metric\n",
    "            rmse = root_mean_squared_error(y_val, y_pred)\n",
    "            \n",
    "            # Log performance metric\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Xgboost Hyper-parameter Optimization\", nested=True):\n",
    "        search_space = {\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "            'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "            'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "            'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10,\n",
    "            trials=Trials()\n",
    "        )\n",
    "        best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "        best_params[\"seed\"] = 42\n",
    "        best_params[\"objective\"] = \"reg:squarederror\"\n",
    "        \n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def train_best_model(X_train, X_val, y_train, y_val, dv, best_params) -> None:\n",
    "    \"\"\"train a model with best hyperparams and write everything out\"\"\"\n",
    "\n",
    "    with mlflow.start_run(\"Best model ever\"):\n",
    "        train = xgb.DMatrix(X_train, label=y_train)\n",
    "        valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        # Log a fit model instance\n",
    "        booster = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=10\n",
    "        )\n",
    "\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "        with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "        \n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def main_flow(year: int, month_train: int, month_val: int) -> None:\n",
    "    \"\"\"The main training pipeline\"\"\"\n",
    "    \n",
    "    train_path = f\"../data/green_tripdata_{year}-{month_train}.parquet\"\n",
    "    val_path = f\"../data/green_tripdata_{year}-{month_val}.parquet\"\n",
    "    \n",
    "    # MLflow settings\n",
    "    dagshub.init(url=\"https://dagshub.com/zapatacc/nyc-taxi-time-prediction\", mlflow=True)\n",
    "    \n",
    "    MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "    \n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment-prefect\")\n",
    "\n",
    "    # Load\n",
    "    df_train = read_data(train_path)\n",
    "    df_val = read_data(val_path)\n",
    "\n",
    "    # Transform\n",
    "    X_train, X_val, y_train, y_val, dv = add_features(df_train, df_val)\n",
    "    \n",
    "    # Hyper-parameter Tunning\n",
    "    best_params = hyper_parameter_tunning(X_train, X_val, y_train, y_val, dv)\n",
    "    \n",
    "    # Train\n",
    "    train_best_model(X_train, X_val, y_train, y_val, dv, best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c15fc97b6ed92d",
   "metadata": {},
   "source": [
    "Pero falta todavía registrar dicho modelo en el `model registry`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b38ea83bc246e8",
   "metadata": {},
   "source": [
    "Pero qué sucede? Necesitamos el `run_id`. No quiero ingresarlo manualmente.\n",
    "\n",
    "## Actividad en clase:\n",
    "### A los 3 primeros que logren terminar la siguiente actividad les subiré el puntaje a 100 de la tarea con menor calificación actualmente.\n",
    "\n",
    "1. Crear una nueva task para agregar el modelo con mejor métrica al `model registry`.\n",
    "2. El modelo debe tener como nombre `nyc-taxi-model-prefect` en el `model registry` para diferenciarlo del modelo que ya tenemos actualmente.\n",
    "3. El registro debe ser automático, puede hacer uso de la función `mlflow.register_model` que ya saben utilizar de la tarea anterior.\n",
    "4. Si recuerdan, esa función requiere un `run_uri`, el cual se conformaba algo como `f\"runs:/{run_id}/model\"`. Nosotros buscabamos manualmente el `run_id`, pero `mlflow` tiene manera de hacer una query y ordenar los resultados por métrica en orden ascendente y devolver dicho `run_id`.\n",
    "5. Busque dicha función e impleméntela en la lógica para que sea de manera automática la obtención del `run_uri`. Use la documentación oficial de `mlflow`, saber leer y usar la documentación es una skill que como Data Scientist también debe tener. PROHIBIDO EL USO DE CHATGPT.\n",
    "6. Asígnele a esa versión del modelo registrado, el alias de `@champion`. Para ello utilice la función `set_registered_model_alias` que ya sabe usar de la tarea pasada. Hint: Recuerde usar el cliente `MlflowClient` con el Tracking URI correspondiente.\n",
    "7. Corra el pipeline y verifique que se haya registrado el modelo en el `model registry`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tarea 7\n",
    "\n",
    "1. Terminar la actividad anterior.\n",
    "2. Crear un nuevo script llamado `train_challenger.py` dentro del directorio `training pipeline`\n",
    "3. Convertir la tarea 5 en un `flow` (en donde entrenó dos modelos, al mejor le asignó el alias `@challenger` comparó el desempeño con el `@champion`).\n",
    "4. El `flow` debe escoger quién es el nuevo `@champion` y asignarle el alias respectivo.\n",
    "5. Recuerde definir las `task` que considere\n",
    "6. Recuerde que los nombres de los `flow` deben ser únicos, que no interfiera con el `flow` del ejercicio anterior.\n",
    "7. Use el mismo nombre del experimeto del ejercicio anterior `nyc-taxi-experiment-prefect`\n",
    "8. Registre los modelos en el mismo `Model Registry` del ejercicio anterior `nyc-taxi-model-prefect`\n",
    "9. Cree un `PR` con los cambios hecho en esta branch hacia `main`\n",
    "\n",
    "## Fecha de entrega:\n",
    "Martes 8 de Octubre antes de la clase: 19:55"
   ],
   "id": "507db28cb67abd98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e547e097758c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
